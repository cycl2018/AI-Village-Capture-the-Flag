{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36885606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"message\": \"ERROR\"}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "from IPython.display import Image as Ima\n",
    "from IPython.display import clear_output, display\n",
    "from PIL import Image as Im\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import base64\n",
    "import shutil\n",
    "import warnings\n",
    "import random\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "dir_name = \"/kaggle/input/ai-village-ctf\"\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd5ca3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.uniform(0, 1, (1, 32, 32, 1))\n",
    "\n",
    "try:\n",
    "    response = requests.post(\"https://inference.fly.dev/score\", data = json.dumps({\"input\": x.tolist()}))\n",
    "    print(response.text)\n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"Connection problems. Contact the CTF organizers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fa9ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "for cur in range(6):\n",
    "    best_pro = -100\n",
    "    best_data = np.zeros((1, 32, 32, 1))\n",
    "    for _ in range(200000):\n",
    "        i = random.randint(0, 31)\n",
    "        j = random.randint(0, 31)\n",
    "        k = random.randint(0, 1)\n",
    "        tmp = best_data[0, i, j, 0]\n",
    "        best_data[0, i, j, 0] = k\n",
    "        response = requests.post(\"https://inference.fly.dev/score\", data = json.dumps({\"input\": best_data.tolist()}))\n",
    "        response = json.loads(response.text)\n",
    "        if response['outputs'][0][cur] > best_pro:\n",
    "            best_pro = response['outputs'][0][cur]\n",
    "        else:\n",
    "            best_data[0, i, j, 0] = tmp\n",
    "    print(cur, best_pro, best_data.shape)\n",
    "    # best_data[best_data > 0.5] = 1.0\n",
    "    # best_data[best_data <= 0.5] = 0.0\n",
    "    imgs.append(best_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22161f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(imgs[0][0, :, :, :]) \n",
    "plt.imshow(imgs[1][0, :, :, :]) \n",
    "plt.imshow(imgs[2][0, :, :, :]) \n",
    "plt.imshow(imgs[3][0, :, :, :]) \n",
    "plt.imshow(imgs[4][0, :, :, :]) \n",
    "plt.imshow(imgs[5][0, :, :, :]) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vqa_prompt",
   "language": "python",
   "name": "vqa_prompt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
